{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CRAWLING   ì¹´í…Œê³ ë¦¬ì—ì„œ ì¥ë¥´ë§Œ / top100 ì›”ê°„/ì£¼ê°„?  ì¥ë¥´ë³„ ë§í¬\n",
    "- 01_ë¡œë§¨ìŠ¤ ~ 1833  top100  ì£¼ê°„ > https://series.naver.com/novel/top100List.series?rankingTypeCode=WEEKLY&categoryCode=201\n",
    "\n",
    "- 02_ë¡œíŒ ~ 619  top100  ì£¼ê°„ > https://series.naver.com/novel/top100List.series?rankingTypeCode=WEEKLY&categoryCode=207\n",
    "\n",
    "- 03_íŒíƒ€ì§€ ~493   top100  ì£¼ê°„ > https://series.naver.com/novel/top100List.series?rankingTypeCode=WEEKLY&categoryCode=202\n",
    "\n",
    "- 04_í˜„íŒ ~401  top100  ì£¼ê°„ > https://series.naver.com/novel/top100List.series?rankingTypeCode=WEEKLY&categoryCode=208\n",
    "\n",
    "- 05_ë¬´í˜‘ ~218  top100  ì£¼ê°„ > https://series.naver.com/novel/top100List.series?rankingTypeCode=WEEKLY&categoryCode=206\n",
    "\n",
    "- n06_ë¯¸ìŠ¤í„°ë¦¬ ~288  top100  ì›”ê°„  8í¸ > https://series.naver.com/novel/top100List.series?rankingTypeCode=MONTHLY&categoryCode=203\n",
    "- 06_ë¯¸ìŠ¤í„°ë¦¬ ~288  ì¥ë¥´ í‰ì ìˆœ  12í¸ https://series.naver.com/novel/categoryProductList.series?categoryTypeCode=genre&genreCode=203&orderTypeCode=star_score&is&isFinished=false\n",
    "\n",
    "- 07_ë¼ì´íŠ¸ë…¸ë²¨ ~39  top100  ì›”ê°„  11í¸ > https://series.naver.com/novel/top100List.series?rankingTypeCode=MONTHLY&categoryCode=205\n",
    "- 07_ë¼ì´íŠ¸ë…¸ë²¨ ~39  ì¥ë¥´ í‰ì ìˆœ  9í¸ > https://series.naver.com/novel/categoryProductList.series?categoryTypeCode=genre&genreCode=205&orderTypeCode=star_score&is&isFinished=false\n",
    "\n",
    "- 08_BL ~401   top100  ì£¼ê°„ > https://series.naver.com/novel/top100List.series?rankingTypeCode=WEEKLY&categoryCode=209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ https://series.naver.com/novel/categoryProductList.series?categoryTypeCode=genre&genreCode=203&orderTypeCode=star_score&is&isFinished=false â†’ Top ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§ ì‹¤íŒ¨ â†’ í‰ì ìˆœ í¬ë¡¤ë§ ì‹¤í–‰\n",
      "âš ï¸ https://series.naver.com/novel/categoryProductList.series?categoryTypeCode=genre&genreCode=205&orderTypeCode=star_score&is&isFinished=false â†’ Top ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§ ì‹¤íŒ¨ â†’ í‰ì ìˆœ í¬ë¡¤ë§ ì‹¤í–‰\n",
      "âœ… ì´ 185ê°œì˜ ì†Œì„¤ URLì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ“ JSON íŒŒì¼ ê²½ë¡œ: sample/wn_ns_sample_20250217_143846.json\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "from urllib.parse import urljoin\n",
    "from datetime import datetime\n",
    "\n",
    "# ğŸ“Œ í¬ë¡¤ë§í•  URL ë¦¬ìŠ¤íŠ¸\n",
    "url_list = [\n",
    "    \"https://series.naver.com/novel/top100List.series?rankingTypeCode=WEEKLY&categoryCode=201\",\n",
    "    \"https://series.naver.com/novel/top100List.series?rankingTypeCode=WEEKLY&categoryCode=207\",\n",
    "    \"https://series.naver.com/novel/top100List.series?rankingTypeCode=WEEKLY&categoryCode=202\",\n",
    "    \"https://series.naver.com/novel/top100List.series?rankingTypeCode=WEEKLY&categoryCode=208\",\n",
    "    \"https://series.naver.com/novel/top100List.series?rankingTypeCode=WEEKLY&categoryCode=206\",\n",
    "    \"https://series.naver.com/novel/top100List.series?rankingTypeCode=MONTHLY&categoryCode=203\",\n",
    "    \"https://series.naver.com/novel/categoryProductList.series?categoryTypeCode=genre&genreCode=203&orderTypeCode=star_score&is&isFinished=false\",\n",
    "    \"https://series.naver.com/novel/top100List.series?rankingTypeCode=MONTHLY&categoryCode=205\",\n",
    "    \"https://series.naver.com/novel/categoryProductList.series?categoryTypeCode=genre&genreCode=205&orderTypeCode=star_score&is&isFinished=false\",\n",
    "    \"https://series.naver.com/novel/top100List.series?rankingTypeCode=WEEKLY&categoryCode=209\",\n",
    "]\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# ğŸ“Œ HTML ê°€ì ¸ì˜¤ê¸°\n",
    "def fetch_html(url):\n",
    "    try:\n",
    "        req = urllib.request.Request(url, headers=headers)\n",
    "        with urllib.request.urlopen(req) as response:\n",
    "            return response.read()\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ [ì˜¤ë¥˜] {url} í¬ë¡¤ë§ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "# ğŸ“Œ ì†Œì„¤ URL í¬ë¡¤ë§ í•¨ìˆ˜ (Top ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§ ì‹¤íŒ¨ ì‹œ í‰ì ìˆœ í¬ë¡¤ë§)\n",
    "def get_novel_urls(url):\n",
    "    sourcecode = fetch_html(url)\n",
    "    if sourcecode is None:\n",
    "        return []  # í¬ë¡¤ë§ ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\n",
    "\n",
    "    soup = BeautifulSoup(sourcecode, \"html.parser\")\n",
    "    novel_urls = set()  # ì¤‘ë³µ ë°©ì§€\n",
    "\n",
    "    # âœ… 1ì°¨ í¬ë¡¤ë§: ì£¼ê°„ Top ë¦¬ìŠ¤íŠ¸\n",
    "    for li in soup.select(\"div.comic_lst_thum_wrap ul.comic_top_lst li\"):\n",
    "        link = li.find(\"a\", class_=\"pic\")\n",
    "        if link and \"href\" in link.attrs:\n",
    "            full_url = urljoin(\"https://series.naver.com\", link[\"href\"])\n",
    "            novel_urls.add(full_url)\n",
    "\n",
    "    # ğŸ”„ ë§Œì•½ ì£¼ê°„ Top ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§ì´ ì‹¤íŒ¨í–ˆë‹¤ë©´? ğŸ‘‰ í‰ì ìˆœ í¬ë¡¤ë§ ì‹¤í–‰\n",
    "    if not novel_urls:\n",
    "        print(f\"âš ï¸ {url} â†’ Top ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§ ì‹¤íŒ¨ â†’ í‰ì ìˆœ í¬ë¡¤ë§ ì‹¤í–‰\")\n",
    "        for li in soup.select(\"div.lst_thum_wrap ul.lst_list li\"):\n",
    "            link = li.find(\"a\", class_=\"pic\")\n",
    "            if link and \"href\" in link.attrs:\n",
    "                href_value = link[\"href\"]\n",
    "                if \"categoryProductList.series\" not in href_value:\n",
    "                    full_url = urljoin(\"https://series.naver.com\", href_value)\n",
    "                    novel_urls.add(full_url)\n",
    "\n",
    "    return list(novel_urls)\n",
    "\n",
    "# ğŸ“Œ JSON ì €ì¥ í•¨ìˆ˜\n",
    "def save_json(path: str, file_name: str, data: list):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    with open(os.path.join(path, file_name), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# âœ… ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    all_novel_urls = set()  # ì „ì²´ í¬ë¡¤ë§ëœ URL ì €ì¥ (ì¤‘ë³µ ë°©ì§€)\n",
    "\n",
    "    for url in url_list:\n",
    "        novel_urls = get_novel_urls(url)\n",
    "        all_novel_urls.update(novel_urls)  # ìƒˆë¡œìš´ URL ì¶”ê°€\n",
    "\n",
    "    # ì €ì¥ ê²½ë¡œ ìƒì„±\n",
    "    DATA_DIR = \"sample\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")  # íŒŒì¼ëª… ìë™ ë³€ê²½\n",
    "    file_name = f\"wn_ns_sample_{timestamp}.json\"\n",
    "\n",
    "    # JSON íŒŒì¼ ì €ì¥\n",
    "    save_json(DATA_DIR, file_name, list(all_novel_urls))\n",
    "\n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    print(f\"âœ… ì´ {len(all_novel_urls)}ê°œì˜ ì†Œì„¤ URLì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(f\"ğŸ“ JSON íŒŒì¼ ê²½ë¡œ: {DATA_DIR}/{file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### í˜ì´ì§€ ìš”ì†Œ ì¶”ì¶œ  (ë¯¸ì™„ì„±)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import lxml\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from urllib.parse import urlparse, urlunparse\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "naver_id = os.getenv(\"NAVER_ID\")\n",
    "naver_pw = os.getenv(\"NAVER_PWD\")\n",
    "\n",
    "def save_cookies(driver, path):\n",
    "    with open(path, \"wb\") as file:\n",
    "        pickle.dump(driver.get_cookies(), file)\n",
    "\n",
    "def load_cookies(driver, path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"rb\") as file:\n",
    "            cookies = pickle.load(file)\n",
    "            for cookie in cookies:\n",
    "                driver.add_cookie(cookie)\n",
    "\n",
    "def login_naver(driver):\n",
    "    driver.get(\"https://nid.naver.com/nidlogin.login\")\n",
    "    time.sleep(2)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°\n",
    "\n",
    "    driver.execute_script(\"document.getElementById('id').value = arguments[0]\", naver_id)\n",
    "    driver.execute_script(\"document.getElementById('pw').value = arguments[0]\", naver_pw)\n",
    "    driver.find_element(By.ID, \"log.login\").click()\n",
    "    time.sleep(5)  # ë¡œê·¸ì¸ ì™„ë£Œ ëŒ€ê¸°\n",
    "    save_cookies(driver, \"naver_cookies.pkl\")\n",
    "\n",
    "def initialize_driver():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")  # ë¸Œë¼ìš°ì € ì°½ì„ ë„ìš°ì§€ ì•ŠìŒ\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    return driver\n",
    "\n",
    "def crawling(url, driver):\n",
    "    driver.get(url)\n",
    "    time.sleep(3)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°\n",
    "    \n",
    "    series_novel = {\n",
    "        \"type\": \"ì›¹ì†Œì„¤\",\n",
    "        \"platform\": \"ë„¤ì´ë²„ ì‹œë¦¬ì¦ˆ\"\n",
    "    }\n",
    "\n",
    "    \n",
    "    try:\n",
    "        title_selector = r\"#content > div.end_head > h2\"\n",
    "        title_element = driver.find_element(By.CSS_SELECTOR, title_selector).text\n",
    "    except:\n",
    "        title_element = \"-\"\n",
    "    series_novel[\"title\"] = title_element\n",
    "\n",
    "\n",
    "    try:\n",
    "        status_selector = r\"#content > ul.end_info.NE\\=a\\:nvi > li > ul > li:nth-child(1) > span\"\n",
    "        status_element = driver.find_element(By.CSS_SELECTOR, status_selector).text\n",
    "    except:\n",
    "        status_element = \"-\"\n",
    "    series_novel[\"status\"] = status_element\n",
    "    \n",
    "\n",
    "    try:\n",
    "        thumbnail_selector = r\"#container > div.aside.NE\\\\=a\\\\:nvi > span.pic_area > img\"\n",
    "        thumbnail_element = driver.find_element(By.CSS_SELECTOR, thumbnail_selector).get_attribute(\"src\")\n",
    "    except:\n",
    "        try:\n",
    "            thumbnail_selector = r'//*[@id=\"container\"]/div[1]/a/img'\n",
    "            thumbnail_element = driver.find_element(By.XPATH, thumbnail_selector).get_attribute(\"src\")\n",
    "        except:\n",
    "            try:\n",
    "                thumbnail_selector = r'//*[@id=\"container\"]/div[1]/span/img'\n",
    "                thumbnail_element = driver.find_element(By.XPATH, thumbnail_selector).get_attribute(\"src\")\n",
    "            except:\n",
    "                thumbnail_element = \"-\"\n",
    "    series_novel[\"thumbnail\"] = thumbnail_element\n",
    "\n",
    "\n",
    "    try:\n",
    "        genre_selector = r\"#content > ul.end_info.NE\\=a\\:nvi > li > ul > li:nth-child(2) > span > a\"\n",
    "        genre_element = driver.find_element(By.CSS_SELECTOR, genre_selector).text\n",
    "    except:\n",
    "        genre_element = \"-\"\n",
    "    series_novel[\"genre\"] = genre_element\n",
    "\n",
    "\n",
    "    try:\n",
    "        views_selector = r\"-\"\n",
    "        views_element = driver.find_element(By.CSS_SELECTOR, views_selector).text\n",
    "    except:\n",
    "        views_element = \"-\"\n",
    "    series_novel[\"views\"] = views_element\n",
    "\n",
    "\n",
    "    try:\n",
    "        rating_selector = r\"#content > div.end_head > div.score_area > em\"\n",
    "        rating_element = driver.find_element(By.CSS_SELECTOR, rating_selector).text\n",
    "        rating_element = float(rating_element)\n",
    "    except:\n",
    "        rating_element = \"-\"\n",
    "    series_novel[\"rating\"] = rating_element\n",
    "\n",
    "\n",
    "    try:\n",
    "        like_selector = r\"#content > div.end_head > div.user_action_area > ul > li:nth-child(2) > div > a > em\"\n",
    "        like_element = driver.find_element(By.CSS_SELECTOR, like_selector).text\n",
    "        like_element = int(like_element.replace(\",\", \"\"))   \n",
    "    except:\n",
    "        like_element = \"-\"\n",
    "    series_novel[\"like\"] = like_element\n",
    "\n",
    "\n",
    "    try:\n",
    "        CLICKER_SELECTOR = \"#content > div.end_dsc > div:nth-child(1) > span > a\"\n",
    "        driver.find_element(By.CSS_SELECTOR, CLICKER_SELECTOR).click()\n",
    "        synopsis_selector = \"#content > div.end_dsc.open > div:nth-child(2)\"\n",
    "        synopsis_element = driver.find_element(By.CSS_SELECTOR, synopsis_selector).text\n",
    "    except:\n",
    "        try:\n",
    "            synopsis_selector = r'//*[@id=\"content\"]/div[2]/div'\n",
    "            synopsis_element = driver.find_element(By.XPATH, synopsis_selector).text\n",
    "        except:\n",
    "            synopsis_element = \"-\"\n",
    "    series_novel[\"synopsis\"] = synopsis_element\n",
    "\n",
    "    try:\n",
    "        keywords_selector = r\"-\"\n",
    "        keywords_element = driver.find_element(By.CSS_SELECTOR, keywords_selector).text\n",
    "        keywords_element = keywords_element.replace(\"#\", \"\")\n",
    "        keywords_element = keywords_element.split(\"\\n\")\n",
    "    except:\n",
    "        keywords_element = \"-\"\n",
    "    series_novel[\"keywords\"] = keywords_element\n",
    "\n",
    "\n",
    "    try:\n",
    "        author_selector = r\"#content > ul.end_info.NE\\=a\\:nvi > li > ul > li:nth-child(3) > a\"\n",
    "        author_element = driver.find_element(By.CSS_SELECTOR, author_selector).text\n",
    "    except:\n",
    "        author_element = \"-\"\n",
    "    series_novel[\"author\"] = author_element\n",
    "\n",
    "\n",
    "    try:\n",
    "        illustrator_selector = r\"-\"\n",
    "        illustrator_element = driver.find_element(By.CSS_SELECTOR, illustrator_selector).text\n",
    "    except:\n",
    "        illustrator_element = \"-\"\n",
    "    series_novel[\"illustrator\"] = illustrator_element\n",
    "\n",
    "\n",
    "    try:                     \n",
    "        age_rating_selector = r\"#content > ul.end_info.NE\\=a\\:nvi > li > ul > li:nth-child(6)\"\n",
    "        age_rating_element = driver.find_element(By.CSS_SELECTOR, age_rating_selector).text\n",
    "    except:\n",
    "        try:\n",
    "            age_rating_selector = r\"#content > ul.end_info.NE\\=a\\:nvi > li > ul > li:nth-child(6)\"\n",
    "            age_rating_element = driver.find_element(By.CSS_SELECTOR, age_rating_selector).text\n",
    "            exclude_keywords = [\"ê·¸ë¦¼\", \"ì¶œíŒì‚¬\"]\n",
    "            if not any(keyword in  age_rating_element for keyword in exclude_keywords):\n",
    "                age_rating_element = int(age_rating_element)\n",
    "        except:\n",
    "            try:\n",
    "                age_rating_selector = r\"#content > ul.end_info.NE\\=a\\:nvi > li > ul > li:nth-child(5)\"\n",
    "                age_rating_element = driver.find_element(By.CSS_SELECTOR, age_rating_selector).text\n",
    "                exclude_keywords = [\"ê·¸ë¦¼\", \"ì¶œíŒì‚¬\"]\n",
    "                if not any(keyword in  age_rating_element for keyword in exclude_keywords):\n",
    "                    age_rating_element = int(age_rating_element)\n",
    "                else:\n",
    "                    age_rating_element = \"-\"\n",
    "            except:\n",
    "                try:\n",
    "                    age_rating_selector = r'//*[@id=\"content\"]/ul[1]/li/ul/li[5]' \n",
    "                    age_rating_element = driver.find_element(By.XPATH, age_rating_selector).text\n",
    "                    exclude_keywords = [\"ê·¸ë¦¼\", \"ì¶œíŒì‚¬\"]\n",
    "                except:\n",
    "                    age_rating_element = \"-\"\n",
    "    series_novel[\"age_rating\"] = age_rating_element\n",
    "\n",
    "    free_selector = r\"#content > div.end_title_fixed_price_sign.NE\\=a\\:nvi > div > div.area_text_information > strong\"\n",
    "    wait_selector = r\"#container > div.aside.NE\\=a\\:nvi > span > em.ico_end_head.daily_free2\"\n",
    "    price_selector = r\"#content > div.area_ebook_price_information > div > dl > dd > div > div.area_price\"\n",
    "\n",
    "\n",
    "    try:\n",
    "        driver.find_element(By.CSS_SELECTOR, free_selector)\n",
    "        price_element = driver.find_element(By.CSS_SELECTOR, free_selector).text.get_attribute(\"ë¬´ë£Œ\")\n",
    "    except:\n",
    "        try:\n",
    "            driver.find_element(By.CSS_SELECTOR, wait_selector)\n",
    "            price_element = driver.find_element(By.CSS_SELECTOR, wait_selector).text\n",
    "        except:\n",
    "            try:\n",
    "                price_element = driver.find_element(By.CSS_SELECTOR, price_selector).text\n",
    "            except:\n",
    "                price_element = \"-\"\n",
    "    series_novel[\"price\"] = price_element\n",
    "    \n",
    "\n",
    "    try:\n",
    "        episode_selector = r\"#content > h5 > strong\"\n",
    "        episode_element = driver.find_element(By.CSS_SELECTOR, episode_selector).text\n",
    "        episode_element[\"episode\"] = int(episode_element)\n",
    "    except:\n",
    "        try:\n",
    "            episode_selector = \"#content > h5.end_total_episode > strong\"\n",
    "            episode_element = driver.find_element(By.CSS_SELECTOR, episode_selector).text\n",
    "            episode_element = int(episode_element)\n",
    "        except:\n",
    "            episode_element = \"-\"\n",
    "    series_novel[\"episode\"] = episode_element\n",
    "    \n",
    "    URL = url + \"?tab_type=overview\"\n",
    "    driver.get(URL)\n",
    "    series_novel[\"url\"] = url\n",
    "    \n",
    "    return series_novel\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    driver = initialize_driver()\n",
    "    \n",
    "    # ì¿ í‚¤ ë¡œë“œ ì‹œë„\n",
    "    driver.get(\"https://www.naver.com\")\n",
    "    load_cookies(driver, \"naver_cookies.pkl\")\n",
    "    driver.get(\"https://nid.naver.com/nidlogin.login\")\n",
    "    time.sleep(2)\n",
    "    \n",
    "    if \"nid.naver.com\" in driver.current_url:  # ë¡œê·¸ì¸ ìœ ì§€ê°€ ì•ˆ ëœ ê²½ìš° ë¡œê·¸ì¸ ì‹¤í–‰\n",
    "        login_naver(driver)\n",
    "    \n",
    "    url_list = []\n",
    "    result = crawling(url, driver)\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "    # í¬ë¡¤ë§ ê²°ê³¼ ì €ì¥\n",
    "    with open(\"crawling_result.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(\"í¬ë¡¤ë§ ê²°ê³¼ ì €ì¥ ì™„ë£Œ!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
