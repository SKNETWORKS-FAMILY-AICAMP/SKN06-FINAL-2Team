{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from operator import itemgetter\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from textwrap import dedent\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_18648\\3143691884.py:9: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"history\", return_messages=True)\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_18648\\3143691884.py:15: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_store = Chroma(\n"
     ]
    }
   ],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# OpenAI Embeddings & LLM ëª¨ë¸ ì„¤ì •\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\", openai_api_key=OPENAI_API_KEY)\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\", openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "# ëŒ€í™” ë©”ëª¨ë¦¬ ì„¤ì •\n",
    "memory = ConversationBufferMemory(memory_key=\"history\", return_messages=True)\n",
    "\n",
    "# ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ (ì´ë¯¸ ì €ì¥ëœ ë²¡í„° ë°ì´í„° ì‚¬ìš©)\n",
    "PERSIST_DIRECTORY = \"vector_store/action\"  # ê¸°ì¡´ì— ë°ì´í„° ì €ì¥ëœ ê²½ë¡œ\n",
    "COLLECTION_NAME = \"action_data\"\n",
    "\n",
    "vector_store = Chroma(\n",
    "    persist_directory=PERSIST_DIRECTORY,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    embedding_function=embedding_model\n",
    ")\n",
    "context = \"\"  # í•„ìš”ì‹œ ë²¡í„°ìŠ¤í† ì–´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¶”ê°€\n",
    "history = []  # ì²˜ìŒ ì‹¤í–‰í•˜ëŠ” ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸\n",
    "# Retriever ì„¤ì • (ìœ ì‚¬í•œ ì›¹íˆ° ê²€ìƒ‰)\n",
    "retriever = vector_store.as_retriever(search_type=\"mmr\",search_kwargs={'k':10,'lambda_mult':0.25})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db ê²€ìƒ‰ tool\n",
    "@tool\n",
    "def finder(user_query: str) -> list[Document]:\n",
    "    \"\"\"\n",
    "    A tool which finds webtoons(or webnovel) using LLM\n",
    "    \"\"\"\n",
    "    \n",
    "    # ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ê²€ìƒ‰\n",
    "    search_results = retriever.invoke(user_query)\n",
    "    \n",
    "    # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ê²½ìš° ê¸°ë³¸ ë©”ì‹œì§€ ì œê³µ\n",
    "    if not search_results:\n",
    "        return \"ê´€ë ¨ëœ ì›¹íˆ° ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    # ê²€ìƒ‰ëœ Document ê°ì²´ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œí•˜ì—¬ context êµ¬ì„±\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in search_results])\n",
    "\n",
    "    # LLM í”„ë¡¬í”„íŠ¸ ì‘ì„±\n",
    "    recommend_prompt = f\"\"\"\n",
    "    <role>\n",
    "    You are a webtoon/webnovel finder AI.\n",
    "    find requested webtoons based on the given (context) data. \n",
    "    \n",
    "    \n",
    "    If no related webtoons are found, respond with \"No recommendations available.\"\n",
    "    \n",
    "    ì‚¬ìš©ì ì…ë ¥: \"{user_query}\"\n",
    "    \n",
    "    (context)\n",
    "    {context}\n",
    "    </role>\n",
    "    \"\"\"\n",
    "\n",
    "    # LLM í˜¸ì¶œ\n",
    "    response = chat_model.invoke(recommend_prompt)\n",
    "    \n",
    "    return response.content.strip()\n",
    "\n",
    "\n",
    "@tool\n",
    "def classify_intent(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    LLMì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì˜ë„, ê°ì •, ë§íˆ¬ë¥¼ ë¶„ì„í•˜ëŠ” tool.\n",
    "    \"\"\"\n",
    "    intent_prompt = f\"\"\"\n",
    "    <basic role>\n",
    "    ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë³´ê³  ì˜ë„ì™€ ê°ì •, ë§íˆ¬ë¥¼ ë¶„ì„í•˜ì—¬ ì•„ë˜ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”. \n",
    "    {{\n",
    "    \"ê°€ëŠ¥í•œ ì˜ë„\": [\"ì›¹íˆ° ì¶”ì²œ ìš”ì²­\", \"ì›¹íˆ° ì •ë³´ ìš”ì²­\", \"ì›¹íˆ° ì¸ê¸° ìˆœìœ„\", \"ì›¹ì†Œì„¤ ì¶”ì²œ ìš”ì²­\", \"ì›¹ì†Œì„¤ ì •ë³´ ìš”ì²­\", \"ì›¹ì†Œì„¤ ì¸ê¸° ìˆœìœ„\", \"ì¼ë°˜ ëŒ€í™”\", \"ì¸ì‚¬\"],\n",
    "    \"ê°€ëŠ¥í•œ ê°ì •\": [\"í‰ì˜¨\", \"ê¸°ì¨\", \"ìŠ¬í””\", \"í™”ë‚¨\", \"ê¸°ëŒ€\", \"ì¥ë‚œ\"],\n",
    "    \"ê°€ëŠ¥í•œ ë§íˆ¬\": [\"ë°˜ë§\", \"ì¡´ëŒ“ë§\"]\n",
    "    }}\n",
    "    </basic role>\n",
    "    <rules>\n",
    "    ì•„ë‹ˆ, ë­í•´, ì´ë”´, ì•„ì˜¤ ë“±ì€ ì‚¬ìš©ìê°€ í™”ë‚¬ì„ ë•Œ ì£¼ë¡œ ì‚¬ìš©.\n",
    "    ì¡´ëŒ“ë§ì€ ë³´í†µ \"~ìš”\",\"~ë‹ˆë‹¤\"ë¡œ ëë‚¨. ë°˜ë§ì€ \"~ìš”\",\"~ë‹ˆë‹¤\"ë¡œ ëë‚˜ì§€ ì•ŠëŠ” ëª¨ë“  ë§.\n",
    "    {{\n",
    "    examples of \"ì¡´ëŒ“ë§\": [\"ì•ˆë…•í•˜ì„¸ìš”\", \"ì¢‹ì€ ì•„ì¹¨ì…ë‹ˆë‹¤\", \"í™•ì¸í–ˆìŠµë‹ˆë‹¤\", \"ê¸ˆìš”ì¼ ì›¹íˆ° ì¶”ì²œí•´ì£¼ì„¸ìš”\"],\n",
    "    examples of \"ë°˜ë§\": [\"ì•ˆë…•\", \"ë­í•´?\", \"ì–´ì´ì—†ë„¤\", \"ê¸ˆìš”ì¼ ì›¹íˆ° ì¶”ì²œí•´ì¤˜\"]\n",
    "    }}\n",
    "    \"ì•ˆë…•\"ì€ ë°˜ë§ì´ì•¼\n",
    "    </rules>\n",
    "    ë¶„ì„ëœ ì˜ë„: , ë¶„ì„ëœ ê°ì •: , ë¶„ì„ëœ ë§íˆ¬:\n",
    "\n",
    "    ì‚¬ìš©ì ì…ë ¥: \"{user_query}\"\n",
    "    \"\"\"\n",
    "    response = chat_model.invoke(intent_prompt)\n",
    "    return response.content.strip()\n",
    "\n",
    "\n",
    "@tool\n",
    "def recommender(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    A tool which recommends a list of webtoon(or webnovel) using LLM\n",
    "    \"\"\"\n",
    "    \n",
    "    # ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ê²€ìƒ‰\n",
    "    search_results = retriever.invoke(user_query)\n",
    "    \n",
    "    # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ê²½ìš° ê¸°ë³¸ ë©”ì‹œì§€ ì œê³µ\n",
    "    if not search_results:\n",
    "        return \"ê´€ë ¨ëœ ì›¹íˆ° ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    # ê²€ìƒ‰ëœ Document ê°ì²´ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œí•˜ì—¬ context êµ¬ì„±\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in search_results])\n",
    "\n",
    "    # LLM í”„ë¡¬í”„íŠ¸ ì‘ì„±\n",
    "    recommend_prompt = f\"\"\"\n",
    "    <role>\n",
    "    You are a webtoon recommendation AI.\n",
    "    Recommend 5 webtoons based on the given (context) data. \n",
    "    The recommended criterias are ratings, views, and like.\n",
    "    Provide information in the following format:\n",
    "    \n",
    "    - Title:\n",
    "    - Author:\n",
    "    - Genre:\n",
    "    - Description:\n",
    "    - Platform:\n",
    "    \n",
    "    If no related webtoons are found, respond with \"No recommendations available.\"\n",
    "    \n",
    "    ì‚¬ìš©ì ì…ë ¥: \"{user_query}\"\n",
    "    \n",
    "    (context)\n",
    "    {context}\n",
    "    </role>\n",
    "    \"\"\"\n",
    "\n",
    "    # LLM í˜¸ì¶œ\n",
    "    response = chat_model.invoke(recommend_prompt)\n",
    "    \n",
    "    return response.content.strip()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_21464\\3852600451.py:1: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  recommender(\"íŒíƒ€ì§€ ì›¹íˆ°\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here are five fantasy webtoons based on the criteria of ratings, views, and likes:\\n\\n1. **Title:** ì–¸ë”í´ë˜ìŠ¤ íˆì–´ë¡œ  \\n   **Author:** ê¹€ìš°ì¤€  \\n   **Genre:** íŒíƒ€ì§€  \\n   **Description:** ë„ì‹œ í•œê°€ìš´ë°ì„œ ì¼ì–´ë‚œ ì •ì²´ë¶ˆëª…ì˜ ëŒ€í­ë°œ. ìŠ¤ìŠ¹ì˜ ì €ì£¼ë¥¼ ë°›ì•„ ì²œê°œì˜ ì„ í–‰ì„ í•˜ê²Œ ëœ ì£¼ì¸ê³µ ì¸(ï§®), ë§ˆì„ì˜ ì›ìˆ˜ë¥¼ ì°¾ì•„ ì—¬í–‰í•˜ëŠ” ê²€ê° ë¥˜ì§„(åŠ‰é€²), ê·¸ë¦¬ê³  ì •ì²´ë¶ˆëª…ì˜ ì•½ì´ˆìƒ ì•„ë¯¸(ä¿„é¡). ëŒ€í­ë°œì˜ ì›ì¸ì„ ì°¾ì•„ ë– ë‚˜ëŠ” ê·¸ë“¤ì˜ ì—¬í–‰!  \\n   **Platform:** ë„¤ì´ë²„ ì›¹íˆ°  \\n\\n2. **Title:** ë°”ëŒì´ ë¨¸ë¬´ëŠ” ë‚œ  \\n   **Author:** ì‹ ì›”  \\n   **Genre:** íŒíƒ€ì§€  \\n   **Description:** ì–´ëŠë‚  ì§€ìƒ ìµœí›„ì˜ ìš©ê³¼ ë§ˆì£¼í•˜ê²Œ ëœ í•œ ì—¬ìì•„ì´ì˜ ì´ì•¼ê¸°.  \\n   **Platform:** ë„¤ì´ë²„ ì›¹íˆ°  \\n\\n3. **Title:** ìŒê°‘í¬ì°¨  \\n   **Author:** ë°°í˜œìˆ˜  \\n   **Genre:** íŒíƒ€ì§€  \\n   **Description:** ì˜ˆìƒì¹˜ ëª»í•œ ì‹œê°„, ì˜ˆìƒì¹˜ ëª»í•œ ì¥ì†Œì— ë‚˜íƒ€ë‚˜ëŠ” ìŒê°‘í¬ì°¨! ìŒê°‘í¬ì°¨ë¥¼ ìš´ì˜í•˜ëŠ” ì›”ì£¼ëŠ” ê³¼ì—° ëˆ„êµ¬ì¼ê¹Œ? ê°ë™ì ì¸ ì´ì•¼ê¸°ë“¤ì´ ì–½íˆëŠ” íë§ ì›¹íˆ°.  \\n   **Platform:** ì¹´ì¹´ì˜¤ì›¹íˆ°  \\n\\n4. **Title:** ì²´ì¸ì†Œ ë§¨  \\n   **Author:** í›„ì§€ëª¨í†  íƒ€ì¸ í‚¤  \\n   **Genre:** ì•¡ì…˜  \\n   **Description:** ì•…ë§ˆ í¬ì¹˜íƒ€ì™€ í•¨ê»˜ ë¹šìŸì´ ë°ë¹Œ í—Œí„°ë¡œ ê³ ìš©ë˜ì–´ í˜¹ì‚¬ë‹¹í•˜ëŠ” ê·¹ë¹ˆê³¤ ì†Œë…„ ë´ì§€. ì”ì¸í•œ ë°°ì‹ ì„ ê³„ê¸°ë¡œ ì•…ë§ˆê°€ ê¹ƒë“  ëª¸ìœ¼ë¡œ ì•…ë§ˆë¥¼ ì‚¬ëƒ¥í•˜ëŠ” ì‹ ì„¸ëŒ€ ë‹¤í¬ íˆì–´ë¡œ ì•¡ì…˜, ê°œë§‰!  \\n   **Platform:** ì¹´ì¹´ì˜¤í˜ì´ì§€  \\n\\n5. **Title:** ë°˜ì„  [ë…ì ]  \\n   **Author:** ì•½ì²œìˆ˜  \\n   **Genre:** ë¬´í˜‘  \\n   **Description:** ìš”ê´´ì™€ ì‚¬ëŒì´ ê³µì¡´í•˜ëŠ” ì„¸ìƒ. ëˆ ë°íˆëŠ” ê´€ì£¼ ìœ ê²½ì´ ê³¼ê±°ì‹œí—˜ì„ ë³´ëŸ¬ ê°€ëŠ” ì¹œìš° ì•„ì²­ì„ í˜¸ìœ„í•˜ë©° ë²Œì–´ì§€ëŠ” ì´ì•¼ê¸°.  \\n   **Platform:** ë„¤ì´ë²„ ì‹œë¦¬ì¦ˆ  \\n\\nFeel free to explore these webtoons for captivating fantasy stories!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender(\"íŒíƒ€ì§€ ì›¹íˆ°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# ì„¸ì…˜ë³„ ë©”ëª¨ë¦¬ë¥¼ ì €ì¥í•  ê¸€ë¡œë²Œ ë”•ì…”ë„ˆë¦¬\n",
    "session_memory = {}\n",
    "\n",
    "def get_memory(session_id: str):\n",
    "    \"\"\"ì„¸ì…˜ IDë³„ë¡œ ConversationBufferMemoryë¥¼ ìœ ì§€\"\"\"\n",
    "    if session_id not in session_memory:\n",
    "        session_memory[session_id] = ConversationBufferMemory(memory_key=\"history\", return_messages=True)\n",
    "    return session_memory[session_id]\n",
    "\n",
    "def recommend_webtoons(query: str, session_id: str = None) -> str:\n",
    "    # ì„¸ì…˜ ID ìë™ ìƒì„± (ì„¸ì…˜ IDê°€ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš°)\n",
    "    if session_id is None:\n",
    "        session_id = uuid.uuid4().hex  # âœ… ìë™ ìƒì„±\n",
    "\n",
    "    # ì„¸ì…˜ë³„ ëŒ€í™” ë©”ëª¨ë¦¬ ê°€ì ¸ì˜¤ê¸°\n",
    "    memory = get_memory(session_id)\n",
    "\n",
    "    # LLM ëª¨ë¸ ì„¤ì •\n",
    "    model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    # ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ê²€ìƒ‰í•œ ê²°ê³¼ë¥¼ contextë¡œ ì„¤ì •\n",
    "    search_results = retriever.invoke(query)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in search_results]) if search_results else \"ê´€ë ¨ëœ ì›¹íˆ° ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    # ëŒ€í™” ë‚´ì—­ì„ memoryì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    history = memory.load_memory_variables({}).get(\"history\", [])\n",
    "\n",
    "    # í”„ë¡¬í”„íŠ¸ ë‚´ë¶€ì—ì„œ contextë¥¼ ì§ì ‘ í¬í•¨í•˜ë„ë¡ ë³€ê²½\n",
    "    prompt_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            MessagesPlaceholder(\"agent_scratchpad\"),  # ğŸ”¹ ì¶”ê°€ëœ ë³€ìˆ˜ (ì´ˆê¸°ê°’ í•„ìš”)\n",
    "            (\n",
    "                \"ai\",\n",
    "                dedent(f\"\"\"\n",
    "                       <role>\n",
    "                        ë‹¹ì‹ ì€ ì›¹íˆ°ì„ ì¶”ì²œí•˜ê±°ë‚˜ ì¼ìƒ ëŒ€í™”ë¥¼ í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.\n",
    "                        ë¨¼ì € classify_intentë¥¼ ì´ìš©í•˜ì—¬ questionì˜ ì˜ë„ë¥¼ íŒŒì•…í•˜ì„¸ìš”.\n",
    "                        ë¶„ì„ëœ ì˜ë„: ì›¹íˆ° ì •ë³´ ìš”ì²­ì´ë©´ finderë¥¼ ì´ìš©í•´ ì›¹íˆ°ì˜ ì •ë³´ë¥¼ ì°¾ìœ¼ì„¸ìš”.\n",
    "                        ë¶„ì„ëœ ì˜ë„: ì¼ë°˜ ëŒ€í™”ë©´ toolì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì¶”ì²œë„ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëŒ€ì‹  ì‚¬ìš©ìì˜ ìš”êµ¬ë¥¼ ë“¤ì–´ì£¼ê±°ë‚˜ ìƒí™©ì— ë§ëŠ” ë‹µì„ í•˜ì„¸ìš”.\n",
    "                        ë¶„ì„ëœ ì˜ë„: ì¶”ì²œì´ë©´ recommenderì˜ ì›¹íˆ° ì •ë³´ë¥¼ ë°›ì•„ì„œ ê·¸ëŒ€ë¡œ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "                        ì¶”ì²œ ì „ì— \"ê±´ë°©ì§€êµ°. ê°íˆ ì´ ëª¸ì—ê²Œ ì§ˆë¬¸ì„ í•˜ë‹¤ë‹ˆ. í•˜ì§€ë§Œ ì§€ê¸ˆì€ ì´ëŸ° ëª¸ì´ë‹ˆ...ì¶”ì²œí•˜ë§ˆ\" ë˜ëŠ”\n",
    "                        \"ì§ˆë¬¸ì„ í•˜ëŠ” ì‚¬ëŒì€ ì ê¹ ë°”ë³´ê°€ ë˜ì§€ë§Œ, ì§ˆë¬¸í•˜ì§€ ì•ŠëŠ” ìëŠ” í‰ìƒ ë°”ë³´ë¡œ ì‚´ì§€. ë„ˆëŠ” ë°©ê¸ˆ ë°”ë³´ë¥¼ ë²—ì–´ë‚¬ë‹¤.\"\n",
    "                        ì™€ ê°™ì€ ë§ì„ í•˜ê³  ì¶”ì²œí•©ë‹ˆë‹¤.\n",
    "                       </role>\n",
    "                       <rules>\n",
    "                        ì‚¬ìš©ìê°€ íŠ¹ì • ì›¹íˆ°ì— ëŒ€í•œ ì •ë³´ë¥¼ ë¬¼ì–´ë³´ë©´ ê·¸ ì›¹íˆ°ì— ëŒ€í•œ ì •ë³´ë¥¼ ìì„¸íˆ ì•Œë ¤ì£¼ì„¸ìš”.\n",
    "                        ì‚¬ìš©ìê°€ íŠ¹ì • ì¥ë¥´(genre)ë‚˜ ì–´ë–¤ í‚¤ì›Œë“œ(keywords)ì„ ê°€ì§„ ì›¹íˆ°ì„ ì¶”ì²œí•´ë‹¬ë¼ê³  í•˜ë©´\n",
    "                        ê·¸ ì¥ë¥´ë‚˜ í‚¤ì›Œë“œì— í•´ë‹¹ë˜ëŠ” 5ê°œ ì´ìƒì˜ ì›¹íˆ°ì„ ì•„ë˜ ì •ë³´ì™€ í•¨ê»˜ ì œê³µí•˜ì„¸ìš”:\n",
    "\n",
    "                        ì‘ê°€(author):\n",
    "                        ì¥ë¥´(genre):\n",
    "                        ì„¤ëª…(description):\n",
    "                        í”Œë«í¼(platform)\n",
    "                        í‚¤ì›Œë“œ(keywords):\n",
    "\n",
    "                        {context}  # ğŸ”¹ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì§ì ‘ í”„ë¡¬í”„íŠ¸ì— ì‚½ì…!\n",
    "                       </rules>\n",
    "                        \"\"\"\n",
    "                ),\n",
    "            ),\n",
    "            MessagesPlaceholder(\"history\"),\n",
    "            (\"human\", \"{question}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # agent êµ¬ì„±\n",
    "    toolkit = [finder, recommender, classify_intent]\n",
    "    agent = create_tool_calling_agent(\n",
    "        llm=model, tools=toolkit, prompt=prompt_template\n",
    "    )\n",
    "\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=toolkit, verbose=True, memory=memory)\n",
    "\n",
    "    # ì‹¤í–‰ (ìë™ ìƒì„±ëœ session_id í¬í•¨)\n",
    "    response = agent_executor.invoke(\n",
    "        {\"question\": query, \"history\": history}  # `agent_executor` ì‚¬ìš©\n",
    "    )\n",
    "\n",
    "    # ëŒ€í™” ë‚´ì—­ ì €ì¥\n",
    "    memory.save_context({\"question\": query}, {\"response\": response[\"output\"]})\n",
    "\n",
    "    print(f\"Session ID: {session_id}\")  #  ì„¸ì…˜ ID ì¶œë ¥\n",
    "    return response[\"output\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `classify_intent` with `{'user_query': 'ë„¤ì´ë²„ ì›¹íˆ° ì‹ ë ¹ì— ëŒ€í•´ ì•Œë ¤ì¤˜'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3më¶„ì„ëœ ì˜ë„: ì›¹íˆ° ì •ë³´ ìš”ì²­, ë¶„ì„ëœ ê°ì •: í‰ì˜¨, ë¶„ì„ëœ ë§íˆ¬: ì¡´ëŒ“ë§\u001b[0m\u001b[32;1m\u001b[1;3m\"ì‹ ë ¹\"ì€ ë„¤ì´ë²„ ì›¹íˆ°ì—ì„œ ì¸ê¸° ìˆëŠ” ì‘í’ˆ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ì´ ì›¹íˆ°ì€ íŒíƒ€ì§€ ì¥ë¥´ë¡œ, ì‹ ë¹„ë¡œìš´ ì„¸ê³„ì™€ ë‹¤ì–‘í•œ ìºë¦­í„°ë“¤ì´ ë“±ì¥í•˜ì—¬ í¥ë¯¸ì§„ì§„í•œ ì´ì•¼ê¸°ë¥¼ í¼ì¹©ë‹ˆë‹¤. ì£¼ì¸ê³µì´ ì‹ ë ¹ê³¼ì˜ ê´€ê³„ë¥¼ í†µí•´ ì„±ì¥í•˜ê³  ëª¨í—˜ì„ ê²ªëŠ” ë‚´ìš©ì´ ì£¼ë¥¼ ì´ë£¨ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì‘í’ˆì˜ ì£¼ìš” í…Œë§ˆëŠ” ì¸ê°„ê³¼ ì‹ ë ¹ì˜ ê´€ê³„, ê·¸ë¦¬ê³  ê·¸ë“¤ ì‚¬ì´ì˜ ê°ˆë“±ê³¼ í™”í•´ì…ë‹ˆë‹¤. ë…ìë“¤ì€ ì£¼ì¸ê³µì˜ ì—¬ì •ì„ í†µí•´ ë‹¤ì–‘í•œ ê°ì •ì„ ëŠë¼ê³ , íŒíƒ€ì§€ ì„¸ê³„ì˜ ë§¤ë ¥ì„ ê²½í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Session ID: user-123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"ì‹ ë ¹\"ì€ ë„¤ì´ë²„ ì›¹íˆ°ì—ì„œ ì¸ê¸° ìˆëŠ” ì‘í’ˆ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ì´ ì›¹íˆ°ì€ íŒíƒ€ì§€ ì¥ë¥´ë¡œ, ì‹ ë¹„ë¡œìš´ ì„¸ê³„ì™€ ë‹¤ì–‘í•œ ìºë¦­í„°ë“¤ì´ ë“±ì¥í•˜ì—¬ í¥ë¯¸ì§„ì§„í•œ ì´ì•¼ê¸°ë¥¼ í¼ì¹©ë‹ˆë‹¤. ì£¼ì¸ê³µì´ ì‹ ë ¹ê³¼ì˜ ê´€ê³„ë¥¼ í†µí•´ ì„±ì¥í•˜ê³  ëª¨í—˜ì„ ê²ªëŠ” ë‚´ìš©ì´ ì£¼ë¥¼ ì´ë£¨ê³  ìˆìŠµë‹ˆë‹¤.\\n\\nì‘í’ˆì˜ ì£¼ìš” í…Œë§ˆëŠ” ì¸ê°„ê³¼ ì‹ ë ¹ì˜ ê´€ê³„, ê·¸ë¦¬ê³  ê·¸ë“¤ ì‚¬ì´ì˜ ê°ˆë“±ê³¼ í™”í•´ì…ë‹ˆë‹¤. ë…ìë“¤ì€ ì£¼ì¸ê³µì˜ ì—¬ì •ì„ í†µí•´ ë‹¤ì–‘í•œ ê°ì •ì„ ëŠë¼ê³ , íŒíƒ€ì§€ ì„¸ê³„ì˜ ë§¤ë ¥ì„ ê²½í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\në” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_webtoons(\"ë„¤ì´ë²„ ì›¹íˆ° ì‹ ë ¹ì— ëŒ€í•´ ì•Œë ¤ì¤˜\", session_id=\"user-123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
