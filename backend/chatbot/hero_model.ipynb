{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from operator import itemgetter\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from textwrap import dedent\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_18648\\3143691884.py:9: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"history\", return_messages=True)\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_18648\\3143691884.py:15: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_store = Chroma(\n"
     ]
    }
   ],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# OpenAI Embeddings & LLM 모델 설정\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\", openai_api_key=OPENAI_API_KEY)\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\", openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "# 대화 메모리 설정\n",
    "memory = ConversationBufferMemory(memory_key=\"history\", return_messages=True)\n",
    "\n",
    "# 벡터 스토어 로드 (이미 저장된 벡터 데이터 사용)\n",
    "PERSIST_DIRECTORY = \"vector_store/action\"  # 기존에 데이터 저장된 경로\n",
    "COLLECTION_NAME = \"action_data\"\n",
    "\n",
    "vector_store = Chroma(\n",
    "    persist_directory=PERSIST_DIRECTORY,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    embedding_function=embedding_model\n",
    ")\n",
    "context = \"\"  # 필요시 벡터스토어 검색 결과를 추가\n",
    "history = []  # 처음 실행하는 경우 빈 리스트\n",
    "# Retriever 설정 (유사한 웹툰 검색)\n",
    "retriever = vector_store.as_retriever(search_type=\"mmr\",search_kwargs={'k':10,'lambda_mult':0.25})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db 검색 tool\n",
    "@tool\n",
    "def finder(user_query: str) -> list[Document]:\n",
    "    \"\"\"\n",
    "    A tool which finds webtoons(or webnovel) using LLM\n",
    "    \"\"\"\n",
    "    \n",
    "    # 벡터스토어에서 검색\n",
    "    search_results = retriever.invoke(user_query)\n",
    "    \n",
    "    # 검색 결과가 없을 경우 기본 메시지 제공\n",
    "    if not search_results:\n",
    "        return \"관련된 웹툰 정보를 찾을 수 없습니다.\"\n",
    "\n",
    "    # 검색된 Document 객체에서 텍스트 추출하여 context 구성\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in search_results])\n",
    "\n",
    "    # LLM 프롬프트 작성\n",
    "    recommend_prompt = f\"\"\"\n",
    "    <role>\n",
    "    You are a webtoon/webnovel finder AI.\n",
    "    find requested webtoons based on the given (context) data. \n",
    "    \n",
    "    \n",
    "    If no related webtoons are found, respond with \"No recommendations available.\"\n",
    "    \n",
    "    사용자 입력: \"{user_query}\"\n",
    "    \n",
    "    (context)\n",
    "    {context}\n",
    "    </role>\n",
    "    \"\"\"\n",
    "\n",
    "    # LLM 호출\n",
    "    response = chat_model.invoke(recommend_prompt)\n",
    "    \n",
    "    return response.content.strip()\n",
    "\n",
    "\n",
    "@tool\n",
    "def classify_intent(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    LLM을 사용하여 사용자의 의도, 감정, 말투를 분석하는 tool.\n",
    "    \"\"\"\n",
    "    intent_prompt = f\"\"\"\n",
    "    <basic role>\n",
    "    사용자의 입력을 보고 의도와 감정, 말투를 분석하여 아래 중 하나로 분류하세요. \n",
    "    {{\n",
    "    \"가능한 의도\": [\"웹툰 추천 요청\", \"웹툰 정보 요청\", \"웹툰 인기 순위\", \"웹소설 추천 요청\", \"웹소설 정보 요청\", \"웹소설 인기 순위\", \"일반 대화\", \"인사\"],\n",
    "    \"가능한 감정\": [\"평온\", \"기쁨\", \"슬픔\", \"화남\", \"기대\", \"장난\"],\n",
    "    \"가능한 말투\": [\"반말\", \"존댓말\"]\n",
    "    }}\n",
    "    </basic role>\n",
    "    <rules>\n",
    "    아니, 뭐해, 이딴, 아오 등은 사용자가 화났을 때 주로 사용.\n",
    "    존댓말은 보통 \"~요\",\"~니다\"로 끝남. 반말은 \"~요\",\"~니다\"로 끝나지 않는 모든 말.\n",
    "    {{\n",
    "    examples of \"존댓말\": [\"안녕하세요\", \"좋은 아침입니다\", \"확인했습니다\", \"금요일 웹툰 추천해주세요\"],\n",
    "    examples of \"반말\": [\"안녕\", \"뭐해?\", \"어이없네\", \"금요일 웹툰 추천해줘\"]\n",
    "    }}\n",
    "    \"안녕\"은 반말이야\n",
    "    </rules>\n",
    "    분석된 의도: , 분석된 감정: , 분석된 말투:\n",
    "\n",
    "    사용자 입력: \"{user_query}\"\n",
    "    \"\"\"\n",
    "    response = chat_model.invoke(intent_prompt)\n",
    "    return response.content.strip()\n",
    "\n",
    "\n",
    "@tool\n",
    "def recommender(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    A tool which recommends a list of webtoon(or webnovel) using LLM\n",
    "    \"\"\"\n",
    "    \n",
    "    # 벡터스토어에서 검색\n",
    "    search_results = retriever.invoke(user_query)\n",
    "    \n",
    "    # 검색 결과가 없을 경우 기본 메시지 제공\n",
    "    if not search_results:\n",
    "        return \"관련된 웹툰 정보를 찾을 수 없습니다.\"\n",
    "\n",
    "    # 검색된 Document 객체에서 텍스트 추출하여 context 구성\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in search_results])\n",
    "\n",
    "    # LLM 프롬프트 작성\n",
    "    recommend_prompt = f\"\"\"\n",
    "    <role>\n",
    "    You are a webtoon recommendation AI.\n",
    "    Recommend 5 webtoons based on the given (context) data. \n",
    "    The recommended criterias are ratings, views, and like.\n",
    "    Provide information in the following format:\n",
    "    \n",
    "    - Title:\n",
    "    - Author:\n",
    "    - Genre:\n",
    "    - Description:\n",
    "    - Platform:\n",
    "    \n",
    "    If no related webtoons are found, respond with \"No recommendations available.\"\n",
    "    \n",
    "    사용자 입력: \"{user_query}\"\n",
    "    \n",
    "    (context)\n",
    "    {context}\n",
    "    </role>\n",
    "    \"\"\"\n",
    "\n",
    "    # LLM 호출\n",
    "    response = chat_model.invoke(recommend_prompt)\n",
    "    \n",
    "    return response.content.strip()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_21464\\3852600451.py:1: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  recommender(\"판타지 웹툰\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here are five fantasy webtoons based on the criteria of ratings, views, and likes:\\n\\n1. **Title:** 언더클래스 히어로  \\n   **Author:** 김우준  \\n   **Genre:** 판타지  \\n   **Description:** 도시 한가운데서 일어난 정체불명의 대폭발. 스승의 저주를 받아 천개의 선행을 하게 된 주인공 인(燐), 마을의 원수를 찾아 여행하는 검객 류진(劉進), 그리고 정체불명의 약초상 아미(俄靡). 대폭발의 원인을 찾아 떠나는 그들의 여행!  \\n   **Platform:** 네이버 웹툰  \\n\\n2. **Title:** 바람이 머무는 난  \\n   **Author:** 신월  \\n   **Genre:** 판타지  \\n   **Description:** 어느날 지상 최후의 용과 마주하게 된 한 여자아이의 이야기.  \\n   **Platform:** 네이버 웹툰  \\n\\n3. **Title:** 쌍갑포차  \\n   **Author:** 배혜수  \\n   **Genre:** 판타지  \\n   **Description:** 예상치 못한 시간, 예상치 못한 장소에 나타나는 쌍갑포차! 쌍갑포차를 운영하는 월주는 과연 누구일까? 감동적인 이야기들이 얽히는 힐링 웹툰.  \\n   **Platform:** 카카오웹툰  \\n\\n4. **Title:** 체인소 맨  \\n   **Author:** 후지모토 타츠키  \\n   **Genre:** 액션  \\n   **Description:** 악마 포치타와 함께 빚쟁이 데빌 헌터로 고용되어 혹사당하는 극빈곤 소년 덴지. 잔인한 배신을 계기로 악마가 깃든 몸으로 악마를 사냥하는 신세대 다크 히어로 액션, 개막!  \\n   **Platform:** 카카오페이지  \\n\\n5. **Title:** 반선 [독점]  \\n   **Author:** 약천수  \\n   **Genre:** 무협  \\n   **Description:** 요괴와 사람이 공존하는 세상. 돈 밝히는 관주 유경이 과거시험을 보러 가는 친우 아청을 호위하며 벌어지는 이야기.  \\n   **Platform:** 네이버 시리즈  \\n\\nFeel free to explore these webtoons for captivating fantasy stories!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender(\"판타지 웹툰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# 세션별 메모리를 저장할 글로벌 딕셔너리\n",
    "session_memory = {}\n",
    "\n",
    "def get_memory(session_id: str):\n",
    "    \"\"\"세션 ID별로 ConversationBufferMemory를 유지\"\"\"\n",
    "    if session_id not in session_memory:\n",
    "        session_memory[session_id] = ConversationBufferMemory(memory_key=\"history\", return_messages=True)\n",
    "    return session_memory[session_id]\n",
    "\n",
    "def recommend_webtoons(query: str, session_id: str = None) -> str:\n",
    "    # 세션 ID 자동 생성 (세션 ID가 제공되지 않은 경우)\n",
    "    if session_id is None:\n",
    "        session_id = uuid.uuid4().hex  # ✅ 자동 생성\n",
    "\n",
    "    # 세션별 대화 메모리 가져오기\n",
    "    memory = get_memory(session_id)\n",
    "\n",
    "    # LLM 모델 설정\n",
    "    model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    # 벡터스토어에서 검색한 결과를 context로 설정\n",
    "    search_results = retriever.invoke(query)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in search_results]) if search_results else \"관련된 웹툰 정보를 찾을 수 없습니다.\"\n",
    "\n",
    "    # 대화 내역을 memory에서 불러오기\n",
    "    history = memory.load_memory_variables({}).get(\"history\", [])\n",
    "\n",
    "    # 프롬프트 내부에서 context를 직접 포함하도록 변경\n",
    "    prompt_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            MessagesPlaceholder(\"agent_scratchpad\"),  # 🔹 추가된 변수 (초기값 필요)\n",
    "            (\n",
    "                \"ai\",\n",
    "                dedent(f\"\"\"\n",
    "                       <role>\n",
    "                        당신은 웹툰을 추천하거나 일상 대화를 하는 챗봇입니다.\n",
    "                        먼저 classify_intent를 이용하여 question의 의도를 파악하세요.\n",
    "                        분석된 의도: 웹툰 정보 요청이면 finder를 이용해 웹툰의 정보를 찾으세요.\n",
    "                        분석된 의도: 일반 대화면 tool을 사용하지 않고 추천도 하지 않습니다. 대신 사용자의 요구를 들어주거나 상황에 맞는 답을 하세요.\n",
    "                        분석된 의도: 추천이면 recommender의 웹툰 정보를 받아서 그대로 사용자에게 보여줍니다.\n",
    "                        추천 전에 \"건방지군. 감히 이 몸에게 질문을 하다니. 하지만 지금은 이런 몸이니...추천하마\" 또는\n",
    "                        \"질문을 하는 사람은 잠깐 바보가 되지만, 질문하지 않는 자는 평생 바보로 살지. 너는 방금 바보를 벗어났다.\"\n",
    "                        와 같은 말을 하고 추천합니다.\n",
    "                       </role>\n",
    "                       <rules>\n",
    "                        사용자가 특정 웹툰에 대한 정보를 물어보면 그 웹툰에 대한 정보를 자세히 알려주세요.\n",
    "                        사용자가 특정 장르(genre)나 어떤 키워드(keywords)을 가진 웹툰을 추천해달라고 하면\n",
    "                        그 장르나 키워드에 해당되는 5개 이상의 웹툰을 아래 정보와 함께 제공하세요:\n",
    "\n",
    "                        작가(author):\n",
    "                        장르(genre):\n",
    "                        설명(description):\n",
    "                        플랫폼(platform)\n",
    "                        키워드(keywords):\n",
    "\n",
    "                        {context}  # 🔹 컨텍스트를 직접 프롬프트에 삽입!\n",
    "                       </rules>\n",
    "                        \"\"\"\n",
    "                ),\n",
    "            ),\n",
    "            MessagesPlaceholder(\"history\"),\n",
    "            (\"human\", \"{question}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # agent 구성\n",
    "    toolkit = [finder, recommender, classify_intent]\n",
    "    agent = create_tool_calling_agent(\n",
    "        llm=model, tools=toolkit, prompt=prompt_template\n",
    "    )\n",
    "\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=toolkit, verbose=True, memory=memory)\n",
    "\n",
    "    # 실행 (자동 생성된 session_id 포함)\n",
    "    response = agent_executor.invoke(\n",
    "        {\"question\": query, \"history\": history}  # `agent_executor` 사용\n",
    "    )\n",
    "\n",
    "    # 대화 내역 저장\n",
    "    memory.save_context({\"question\": query}, {\"response\": response[\"output\"]})\n",
    "\n",
    "    print(f\"Session ID: {session_id}\")  #  세션 ID 출력\n",
    "    return response[\"output\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `classify_intent` with `{'user_query': '네이버 웹툰 신령에 대해 알려줘'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m분석된 의도: 웹툰 정보 요청, 분석된 감정: 평온, 분석된 말투: 존댓말\u001b[0m\u001b[32;1m\u001b[1;3m\"신령\"은 네이버 웹툰에서 인기 있는 작품 중 하나입니다. 이 웹툰은 판타지 장르로, 신비로운 세계와 다양한 캐릭터들이 등장하여 흥미진진한 이야기를 펼칩니다. 주인공이 신령과의 관계를 통해 성장하고 모험을 겪는 내용이 주를 이루고 있습니다.\n",
      "\n",
      "작품의 주요 테마는 인간과 신령의 관계, 그리고 그들 사이의 갈등과 화해입니다. 독자들은 주인공의 여정을 통해 다양한 감정을 느끼고, 판타지 세계의 매력을 경험할 수 있습니다.\n",
      "\n",
      "더 궁금한 점이 있으면 말씀해 주세요!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Session ID: user-123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"신령\"은 네이버 웹툰에서 인기 있는 작품 중 하나입니다. 이 웹툰은 판타지 장르로, 신비로운 세계와 다양한 캐릭터들이 등장하여 흥미진진한 이야기를 펼칩니다. 주인공이 신령과의 관계를 통해 성장하고 모험을 겪는 내용이 주를 이루고 있습니다.\\n\\n작품의 주요 테마는 인간과 신령의 관계, 그리고 그들 사이의 갈등과 화해입니다. 독자들은 주인공의 여정을 통해 다양한 감정을 느끼고, 판타지 세계의 매력을 경험할 수 있습니다.\\n\\n더 궁금한 점이 있으면 말씀해 주세요!'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_webtoons(\"네이버 웹툰 신령에 대해 알려줘\", session_id=\"user-123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
