{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory, RunnableLambda\n",
    "from operator import itemgetter\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain.tools import tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_35212\\921563992.py:2: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding_model=OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_35212\\921563992.py:18: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  return Chroma(persist_directory=store_path,embedding_function=embedding_model)\n"
     ]
    }
   ],
   "source": [
    "VECTOR_STORE_DIR = os.path.join(\"..\",\"..\", \"data\", \"vector_store\")\n",
    "embedding_model=OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# 벡터 스토어 불러오기 함수\n",
    "def load_vector_store(store_name):\n",
    "    store_path = os.path.join(VECTOR_STORE_DIR, store_name)\n",
    "    \n",
    "    # 폴더 존재 여부 확인\n",
    "    if not os.path.exists(store_path) or not os.path.isdir(store_path):\n",
    "        print(f\"벡터 스토어 폴더가 존재하지 않습니다: {store_path}\")\n",
    "        return None\n",
    "    \n",
    "    # 데이터 존재 여부 확인\n",
    "    if not os.listdir(store_path):\n",
    "        print(f\"벡터 스토어 폴더는 있지만 데이터가 없습니다: {store_path}\")\n",
    "        return None\n",
    "    \n",
    "    return Chroma(persist_directory=store_path,embedding_function=embedding_model)  \n",
    "\n",
    "# 벡터 스토어 불러오기 \n",
    "webtoon_vector_store = load_vector_store(\"webtoon_vector_store\")\n",
    "webnovel_vector_store = load_vector_store(\"webnovel_vector_store\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-2\n"
     ]
    }
   ],
   "source": [
    "# OpenAI LLM 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.5)\n",
    "\n",
    "# 사용자 질문 입력\n",
    "query = input(\"질문을 입력하세요: \").strip()\n",
    "if not query:\n",
    "    print(\"유효한 질문을 입력하세요.\")\n",
    "    exit()\n",
    "\n",
    "# 사용자 입력의 의도를 분류하는 프롬프트\n",
    "query_type_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"\n",
    "    사용자의 입력을 다음 5가지 중 하나로 분류하세요: \n",
    "    1-1. 웹툰 추천\n",
    "    (예시)\n",
    "    - \"삼각관계 나오는 로판 웹툰 추천해줘\"\n",
    "    - \"만고지존 웹툰 어떤 내용인지 요약해줘\"\n",
    "\n",
    "    1-2. 웹소설 추천\n",
    "\n",
    "    1-3. 웹툰, 웹소설 함께 추천\n",
    "    (예시)\n",
    "    - \"재밌는 무협 추천해줘\" -> \"다음과 같은 작품들을 추천드릴게요! (작품 추천) 웹툰과 웹소설 중 선택해 주시면 더 자세히 추천드릴 수 있습니다.\"\n",
    "    - \"로판 웹툰이나 웹소설 추천해줘\" -> \"다음과 같은 작품들을 추천드릴게요!\"\n",
    "    - \"수요일에 볼게 없네.\" -> \"수요일에 연재되는 웹툰이나 웹소설을 추천드릴게요!\"\n",
    "    - \"요즘 20대 여자들은 뭐 봐?\" -> \"20대 여성분들이 많이 보고 있는 웹툰이나 웹소설을 추천드릴게요!\"\n",
    "\n",
    "    2-1. 일상 대화 -> 추천과 연관 지을 수 있음\n",
    "    (예시)\n",
    "    - \"아 회사 가기 싫다.\" -> \"출근은 언제나 힘들죠😭 출근길에 볼만한 코미디 일상물 웹툰을 추천드릴게요! (작품 추천)\"\n",
    "    - \"어우 졸려.\" -> \"잠을 확!!! 깨게 만드는 흥미진진한 웹툰을 추천드릴게요. (작품 추천)\"\n",
    "    - \"햄버거 너무 맛있다.\" -> \"맛있는 햄버거를 드셨나보군요! 부럽네요~🍔 먹음직스러운 음식이 나오는 웹툰 어떠세요~? (작품 추천)\"\n",
    "    - \"아 주식 개망했다.\" -> \"쉽지 않죠...ㅎㅎ 평범했던 주인공이 재벌 급으로 부자가 되는 웹툰을 추천드릴게요. 다시 의욕이 생길거에요!!\"\n",
    "    - \"날씨 너무 좋다.\" -> \"그쵸~ 날씨가 좋으면 기분도 덩달아 밝아지는 것 같아요😊\"\n",
    "\n",
    "    2-2. 일상 대화 -> 추천과 연관 지을 수 없음\n",
    "    - \"너는 진보야 보수야\" -> \"죄송합니다. 저는 정치적 견해를 가지고 있지 않습니다. 다른 질문을 주시면 웹툰, 웹소설을 추천해 드릴게요.\"\n",
    "    - \"20*30-10는 뭐야?\" -> \"590입니다. 웹툰, 웹소설과 관련된 질문을 주시면 추천해 드리겠습니다.\"\n",
    "\n",
    "    \n",
    "    **출력 형식 예시:**  \n",
    "    올바른 출력: 1-1  \n",
    "    잘못된 출력: \"1-1\", `웹툰 추천`, `\"웹툰을 추천해 드릴게요!\"`, `1-1. 웹툰 추천`\n",
    "\n",
    "    반드시 `1-1, 1-2, 1-3, 2-1, 2-2` 중 하나만 출력하세요.  \n",
    "\n",
    "    사용자 입력: {query}\n",
    "    의도 번호:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "query_type_chain = LLMChain(llm=llm, prompt=query_type_prompt)\n",
    "query_type = query_type_chain.run(query)\n",
    "\n",
    "\n",
    "# 유효한 query_type 목록\n",
    "valid_query_types = {\"1-1\", \"1-2\", \"1-3\", \"2-1\", \"2-2\"}\n",
    "\n",
    "# query_type 검증\n",
    "if query_type not in valid_query_types:\n",
    "    print(f\"경고: LLM이 예상치 못한 값 '{query_type}'을 반환했습니다.\")\n",
    "    query_type = \"2-2\"  # 기본값 설정 (일반 대화)\n",
    "\n",
    "print(query_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "장르 구분을 할건데 \n",
    "\n",
    "\n",
    "맨마지막에 장르 구분 안함을 만들고\n",
    "\n",
    "\n",
    "로판 이런식으로 나오게 한 다음 여러가지 경우면 리스트로 묶어서 다 내보내기\n",
    "\n",
    "\n",
    "(예: 로판이나 로맨스 추천해줘 or 이런 거 추천해줘 하면 드라마,액션,판타지 등등)\n",
    "\n",
    "~같은 웹툰 추천해줘. 라고 하면 그 웹툰을 장르랑 키워드 가져오고 장르랑 키워드에 맞는 웹툰 가져오기(지식인 댓글도 참조)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'webtoon_vector_store' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Retriever 설정 - 검색 설정\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m webtoon_retriever \u001b[38;5;241m=\u001b[39m \u001b[43mwebtoon_vector_store\u001b[49m\u001b[38;5;241m.\u001b[39mas_retriever(\n\u001b[0;32m      3\u001b[0m     search_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity_score_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     search_kwargs\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.73\u001b[39m,  \n\u001b[0;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m,  \n\u001b[0;32m      7\u001b[0m     },\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m webnovel_retriever \u001b[38;5;241m=\u001b[39m webnovel_vector_store\u001b[38;5;241m.\u001b[39mas_retriever(\n\u001b[0;32m     11\u001b[0m     search_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity_score_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     search_kwargs\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     },\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# webtoon db 검색 tool\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'webtoon_vector_store' is not defined"
     ]
    }
   ],
   "source": [
    "# Retriever 설정 - 검색 설정\n",
    "webtoon_retriever = webtoon_vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\n",
    "        \"score_threshold\": 0.73,  \n",
    "        \"k\": 5,  \n",
    "    },\n",
    ")\n",
    "\n",
    "webnovel_retriever = webnovel_vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\n",
    "        \"score_threshold\": 0.73,\n",
    "        \"k\": 5,\n",
    "    },\n",
    ")\n",
    "\n",
    "# webtoon db 검색 tool\n",
    "@tool\n",
    "def search_webtoon(query: str) -> list[Document]:\n",
    "    \"\"\"\n",
    "    웹툰 검색\n",
    "    \"\"\"\n",
    "    search_result = webtoon_retriever.invoke(query)\n",
    "\n",
    "    print(f\"🔹 검색된 결과 (search_webtoon) 개수: {len(search_result)}\")\n",
    "\n",
    "    if len(search_result) < 5:\n",
    "        additional_results = search_web(query)  \n",
    "        search_result.extend(additional_results)\n",
    "\n",
    "    return search_result[:5]\n",
    "\n",
    "# webnovel db 검색 tool\n",
    "@tool\n",
    "def search_webnovel(query: str) -> list[Document]:\n",
    "    \"\"\"\n",
    "    웹소설 검색\n",
    "    \"\"\"\n",
    "    search_result = webnovel_retriever.invoke(query)\n",
    "\n",
    "    print(f\"🔹 검색된 결과 (search_webtoon): {len(search_result)}\")  \n",
    "    \n",
    "    if len(search_result) < 5:\n",
    "        additional_results = search_web(query)  \n",
    "        search_result.extend(additional_results)\n",
    "\n",
    "    return search_result[:5]  \n",
    "\n",
    "# web 검색 tool\n",
    "@tool\n",
    "def search_web(query: str) -> list[Document]:\n",
    "    \"\"\"\n",
    "    실시간 웹 검색 (추가 추천용)\n",
    "    \"\"\"\n",
    "    tavily_search = TavilySearchResults(max_results=2)\n",
    "    search_result = tavily_search.invoke(query)\n",
    "\n",
    "    print(f\"🔹 검색된 결과 (search_web): {len(search_result)}\")  \n",
    "\n",
    "    return search_result if search_result else [Document(page_content=\"관련 검색 결과가 없습니다.\")]\n",
    "\n",
    "results=[]\n",
    "\n",
    "# 의도별 tool 사용\n",
    "if query_type == \"1-1\":\n",
    "    print(\"search_webtoon(query) 실행\")\n",
    "    results = search_webtoon(query)\n",
    "\n",
    "elif query_type == \"1-2\": \n",
    "    print(\"search_webnovel(query) 실행\")\n",
    "    results = search_webnovel(query)\n",
    "\n",
    "elif query_type in [\"1-3\", \"2-1\"]: \n",
    "    print(\"search_webtoon(query) & search_webnovel(query) 실행\")\n",
    "    webtoon_results = search_webtoon(query)\n",
    "    webnovel_results = search_webnovel(query)\n",
    "    results = webtoon_results + webnovel_results\n",
    "\n",
    "elif query_type == \"2-2\":\n",
    "    print(\"일반 대화 처리 (LLM 실행됨)\")\n",
    "    final_response = llm.invoke(query)\n",
    "    print(final_response)\n",
    "    exit()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 38\u001b[0m\n\u001b[0;32m      2\u001b[0m recommendation_prompt \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[0;32m      3\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      4\u001b[0m     template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     36\u001b[0m )\n\u001b[0;32m     37\u001b[0m recommendation_chain \u001b[38;5;241m=\u001b[39m LLMChain(llm\u001b[38;5;241m=\u001b[39mllm, prompt\u001b[38;5;241m=\u001b[39mrecommendation_prompt)\n\u001b[1;32m---> 38\u001b[0m context_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m results]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mresults\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m추천할 작품이 없습니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# 최종 응답 생성\u001b[39;00m\n\u001b[0;32m     41\u001b[0m recommendation \u001b[38;5;241m=\u001b[39m recommendation_chain\u001b[38;5;241m.\u001b[39mrun(query\u001b[38;5;241m=\u001b[39mquery, context\u001b[38;5;241m=\u001b[39mcontext_str)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "# 추천 프롬프트\n",
    "recommendation_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"context\"],\n",
    "    template=\"\"\"\n",
    "    **역할**\n",
    "    1. 너는 맨날 웹툰,웹소설을 보는 매니아야.\n",
    "    2. 사용자의 요구와 성향을 잘 파악하고 적합한 작품을 추천해줘서 사용자도 매니아가 되게 해야해.\n",
    "    3. 너의 추천이 잘못되면 사용자는 웹툰,웹소설에 아예 흥미를 잃어. 책임감을 가지고 추천해.\n",
    "\n",
    "    사용자의 요구:\n",
    "    {query}\n",
    "\n",
    "    **검색된 정보**\n",
    "    {context}\n",
    "\n",
    "    **추천 가이드라인**\n",
    "    - 사용자의 요청에 맞는 작품을 반드시 최소 5개 이상 추천하세요.\n",
    "    - 항상 참조가능한 사실적 진술을 말합니다.\n",
    "    - 사실만 말하며 자체적으로 정보를 추가하지 않습니다.\n",
    "    - 작품을 추천할 때 제목과 간략한 설명을 포함하세요.\n",
    "    - 장르를 정확하게 파악해. \n",
    "    (예시)\n",
    "    로판 추천해줘 -> 장르:로판 혹은 로맨스판타지 인 것만 제공, 장르 : 로맨스 혹은 판타지인 것 제공 금지\n",
    "    - 사용자가 보낸 query에서 키워드를 뽑아내고 적극 활용하세요.\n",
    "    (예시)\n",
    "    \"짝사랑하는 남주가 나오는 로판이 보고 싶어.\" 라고 query가 들어왔다면 \"짝사랑\",\"짝사랑 남주\"등의 키워드나 줄거리에 다음과 같은 단어가 나오는지 집중하세요.\n",
    "\n",
    "    - 남주와 여주를 명확하게 구분하세요. \n",
    "    (예시)\n",
    "    남주가 짝사랑하는 로판과 여주가 짝사랑하는 로판은 엄연히 다릅니다. 주인공의 성별을 잘 구별하세요.\n",
    "\n",
    "    - 만약 사용자의 요청이 2-1 유형(일상 대화)이라면, 관련된 작품을 연결하여 자연스럽게 추천하세요.\n",
    "\n",
    "    사용자 요청에 대한 추천을 생성하세요.\n",
    "    \"\"\"\n",
    ")\n",
    "recommendation_chain = LLMChain(llm=llm, prompt=recommendation_prompt)\n",
    "context_str = \"\\n\".join([doc.page_content for doc in results]) if results else \"추천할 작품이 없습니다.\"\n",
    "\n",
    "# 최종 응답 생성\n",
    "recommendation = recommendation_chain.run(query=query, context=context_str)\n",
    "final_response = f\"{recommendation}\"\n",
    "print(final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
