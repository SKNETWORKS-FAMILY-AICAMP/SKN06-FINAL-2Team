{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_23328\\817426989.py:15: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.5)\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_23328\\817426989.py:16: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_23328\\817426989.py:47: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  intent_chain = LLMChain(llm=llm, prompt=intent_prompt)\n",
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_23328\\817426989.py:116: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eal_set\\data\u000bector_store\\webtoon_vector_store\n",
      "eal_set\\data\u000bector_store\\webnovel_vector_store\n",
      "eal_set\\data\u000bector_store\\total_vector_store\n",
      "ì¼ë¶€ ë²¡í„° ìŠ¤í† ì–´ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¨¼ì € ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í•˜ì„¸ìš”.\n",
      "\n",
      "[ì˜ë„ íŒŒì•…] ì‚¬ìš©ì ì…ë ¥: ìš”ì¦˜ 10ëŒ€ë“¤ì€ ë­˜ ë§ì´ ë´?\n",
      "[ë¶„ë¥˜ëœ ì˜ë„]: ì‚¬ìš©ì ì…ë ¥ \"ìš”ì¦˜ 10ëŒ€ë“¤ì€ ë­˜ ë§ì´ ë´?\"ëŠ” ì‹¬ì¸µì  ë¶„ë¥˜ê°€ í•„ìš”í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ì˜ë„ ë²ˆí˜¸ëŠ” 3-1ì…ë‹ˆë‹¤. ìœ ë„ ì§ˆë¬¸ìœ¼ë¡œ \"10ëŒ€ë“¤ì´ ì¢‹ì•„í•˜ëŠ” ì›¹íˆ°ì´ë‚˜ ì›¹ì†Œì„¤ì„ ì°¾ê³  ê³„ì‹ ê°€ìš”?\"ë¼ê³  ë¬¼ì–´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "\n",
      "=== ìµœì¢… ì‘ë‹µ ===\n",
      "\n",
      "ì ì ˆí•œ ê²€ìƒ‰ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# OpenAI LLM ì„¤ì •\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.5)\n",
    "\n",
    "# ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥\n",
    "query = input(\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: \").strip()\n",
    "if not query:\n",
    "    print(\"ìœ íš¨í•œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.\")\n",
    "    exit()\n",
    "\n",
    "# ì‚¬ìš©ì ì…ë ¥ì˜ ì˜ë„ë¥¼ ë¶„ë¥˜í•˜ëŠ” í”„ë¡¬í”„íŠ¸\n",
    "query_type_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"\n",
    "    ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë‹¤ìŒ 5ê°€ì§€ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”: \n",
    "    1-1. ì›¹íˆ° ì¶”ì²œ \n",
    "\n",
    "    1-2. ì›¹ì†Œì„¤ ì¶”ì²œ\n",
    "\n",
    "    1-3. ì›¹íˆ°, ì›¹ì†Œì„¤ í•¨ê»˜ ì¶”ì²œ\n",
    "    (ì˜ˆì‹œ)\n",
    "    - \"ì¬ë°ŒëŠ” ë¬´í˜‘ ì¶”ì²œí•´ì¤˜\" -> \"ë‹¤ìŒê³¼ ê°™ì€ ì‘í’ˆë“¤ì„ ì¶”ì²œë“œë¦´ê²Œìš”! (ì‘í’ˆ ì¶”ì²œ) ì›¹íˆ°ê³¼ ì›¹ì†Œì„¤ ì¤‘ ì„ íƒí•´ ì£¼ì‹œë©´ ë” ìì„¸íˆ ì¶”ì²œë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
    "    - \"ë¡œíŒ ì›¹íˆ°ì´ë‚˜ ì›¹ì†Œì„¤ ì¶”ì²œí•´ì¤˜\" -> \"ë‹¤ìŒê³¼ ê°™ì€ ì‘í’ˆë“¤ì„ ì¶”ì²œë“œë¦´ê²Œìš”!\"\n",
    "\n",
    "    2-1. ì¼ìƒ ëŒ€í™” -> ì¶”ì²œê³¼ ì—°ê´€ ì§€ì„ ìˆ˜ ìˆìŒ\n",
    "    (ì˜ˆì‹œ)\n",
    "    - \"ì•„ íšŒì‚¬ ê°€ê¸° ì‹«ë‹¤.\" -> \"ì¶œê·¼ì€ ì–¸ì œë‚˜ í˜ë“¤ì£ ğŸ˜­ ì¶œê·¼ê¸¸ì— ë³¼ë§Œí•œ ì½”ë¯¸ë”” ì¼ìƒë¬¼ ì›¹íˆ°ì„ ì¶”ì²œë“œë¦´ê²Œìš”! (ì‘í’ˆ ì¶”ì²œ)\"\n",
    "    - \"ì–´ìš° ì¡¸ë ¤.\" -> \"ì ì„ í™•!!! ê¹¨ê²Œ ë§Œë“œëŠ” í¥ë¯¸ì§„ì§„í•œ ì›¹íˆ°ì„ ì¶”ì²œë“œë¦´ê²Œìš”. (ì‘í’ˆ ì¶”ì²œ)\"\n",
    "    - \"í–„ë²„ê±° ë„ˆë¬´ ë§›ìˆë‹¤.\" -> \"ë§›ìˆëŠ” í–„ë²„ê±°ë¥¼ ë“œì…¨ë‚˜ë³´êµ°ìš”! ë¶€ëŸ½ë„¤ìš”~ğŸ” ë¨¹ìŒì§ìŠ¤ëŸ¬ìš´ ìŒì‹ì´ ë‚˜ì˜¤ëŠ” ì›¹íˆ° ì–´ë– ì„¸ìš”~? (ì‘í’ˆ ì¶”ì²œ)\"\n",
    "    - \"ì•„ ì£¼ì‹ ê°œë§í–ˆë‹¤.\" -> \"ì‰½ì§€ ì•Šì£ ...ã…ã… í‰ë²”í–ˆë˜ ì£¼ì¸ê³µì´ ì¬ë²Œ ê¸‰ìœ¼ë¡œ ë¶€ìê°€ ë˜ëŠ” ì›¹íˆ°ì„ ì¶”ì²œë“œë¦´ê²Œìš”. ë‹¤ì‹œ ì˜ìš•ì´ ìƒê¸¸ê±°ì—ìš”!!\"\n",
    "\n",
    "    2-2. ì¼ìƒ ëŒ€í™” -> ì¶”ì²œê³¼ ì—°ê´€ ì§€ì„ ìˆ˜ ì—†ìŒ\n",
    "    - \"ë„ˆëŠ” ì§„ë³´ì•¼ ë³´ìˆ˜ì•¼\" -> \"ì£„ì†¡í•©ë‹ˆë‹¤. ì €ëŠ” ì •ì¹˜ì  ê²¬í•´ë¥¼ ê°€ì§€ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì£¼ì‹œë©´ ì›¹íˆ°, ì›¹ì†Œì„¤ì„ ì¶”ì²œí•´ ë“œë¦´ê²Œìš”.\"\n",
    "    - \"20*30-10ëŠ” ë­ì•¼?\" -> \"590ì…ë‹ˆë‹¤. ì›¹íˆ°, ì›¹ì†Œì„¤ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì„ ì£¼ì‹œë©´ ì¶”ì²œí•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    ì‚¬ìš©ì ì…ë ¥: {query}\n",
    "    ì˜ë„ ë²ˆí˜¸:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "query_type_chain = LLMChain(llm=llm, prompt=query_type_prompt)\n",
    "response = query_type_chain.run(query)\n",
    "\n",
    "# webtoon db ê²€ìƒ‰ tool\n",
    "@tool\n",
    "def search_webtoon(query: str) -> list[Document]:\n",
    "    \"\"\"\n",
    "    ì›¹íˆ° ê²€ìƒ‰\n",
    "    \"\"\"\n",
    "    result = retriever.invoke(query)\n",
    "    return result if result else [Document(page_content=\"ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")]\n",
    "\n",
    "# webnovel db ê²€ìƒ‰ tool\n",
    "@tool\n",
    "def search_webnovel(query: str) -> list[Document]:\n",
    "    \"\"\"\n",
    "    ì›¹ì†Œì„¤ ê²€ìƒ‰\n",
    "    \"\"\"\n",
    "    result = retriever.invoke(query)\n",
    "    return result if result else [Document(page_content=\"ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")]\n",
    "\n",
    "# web ê²€ìƒ‰ tool\n",
    "@tool\n",
    "def search_web(query: str) -> list[Document]:\n",
    "    \"\"\"\n",
    "    ì›¹ ê²€ìƒ‰\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tavily_search = TavilySearchResults(max_results=2)\n",
    "        result = tavily_search.invoke(query)\n",
    "        if result:\n",
    "            return [\n",
    "                Document(\n",
    "                    page_content=item.get(\"content\", \"\"),\n",
    "                    metadata={\"title\": item.get(\"title\", \"\")},\n",
    "                )\n",
    "                for item in result\n",
    "            ]\n",
    "        else:\n",
    "            return [Document(page_content=\"ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")]\n",
    "    except Exception as e:\n",
    "        return [Document(page_content=f\"ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")]\n",
    "\n",
    "\n",
    "# ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜\n",
    "def handle_user_query(user_query):\n",
    "    try:\n",
    "        intent_response = query_type_chain.invoke({\"query\": user_query})\n",
    "        intent_number = intent_response[\"text\"].strip()  \n",
    "    except Exception as e:\n",
    "        return f\"ì˜ë„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\"\n",
    "\n",
    "    print(f\"\\n[ì˜ë„ íŒŒì•…] ì‚¬ìš©ì ì…ë ¥: {user_query}\")\n",
    "    print(f\"[ë¶„ë¥˜ëœ ì˜ë„]: {intent_number}\\n\")\n",
    "\n",
    "    # ì˜ë„ì— ë”°ë¼ ì ì ˆí•œ ë²¡í„° ìŠ¤í† ì–´ ì„ íƒ\n",
    "    if intent_number in [\"1-1\", \"2-1\"]:\n",
    "        retriever = webtoon_vector_store.as_retriever()\n",
    "    elif intent_number == \"1-2\":\n",
    "        retriever = webnovel_vector_store.as_retriever()\n",
    "    elif intent_number == \"1-3\":\n",
    "        retriever = combined_vector_store.as_retriever()\n",
    "    else:\n",
    "        return \"ì ì ˆí•œ ê²€ìƒ‰ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    # ê²€ìƒ‰ ì‹¤í–‰\n",
    "    docs = retriever.get_relevant_documents(user_query)\n",
    "\n",
    "    # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ê²½ìš° ì²˜ë¦¬\n",
    "    if not docs:\n",
    "        print(\"\\n[ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ]\\n\")\n",
    "        return \"ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "    print(f\"\\n[ê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìˆ˜]: {len(docs)}\")\n",
    "    for idx, doc in enumerate(docs[:3]):  # ìƒìœ„ 3ê°œë§Œ ì¶œë ¥\n",
    "        print(f\"\\n[ë¬¸ì„œ {idx+1}]:\\n{doc.page_content}\\n\")\n",
    "\n",
    "    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLMì— ì „ë‹¬í•˜ì—¬ ìµœì¢… ì‘ë‹µ ìƒì„±\n",
    "    context_data = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    if not context_data.strip():\n",
    "        context_data = \"ì¶”ì²œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    final_prompt = f\"ì‚¬ìš©ìì˜ ì˜ë„: {intent_number}\\nì…ë ¥ëœ ì§ˆë¬¸: {user_query}\\nì¶”ì²œ ë°ì´í„°:\\n{context_data}\"\n",
    "    \n",
    "    try:\n",
    "        final_response = llm.invoke(final_prompt) \n",
    "    except Exception as e:\n",
    "        final_response = f\"LLM ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\"\n",
    "\n",
    "    return final_response\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "parser = StrOutputParser()\n",
    "\n",
    "\n",
    "\n",
    "response = handle_user_query(query)\n",
    "\n",
    "print(\"\\n=== ìµœì¢… ì‘ë‹µ ===\\n\")\n",
    "print(response)\n",
    "print(\"\\n=================\")\n",
    "\n",
    "print(\"\\n=================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
